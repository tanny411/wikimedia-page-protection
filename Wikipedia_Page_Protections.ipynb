{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying Wikipedia Page Protections\n",
    "This notebook provides a tutorial for how to study [page protections](https://en.wikipedia.org/wiki/Wikipedia:Protection_policy) on Wikipedia either via the [Mediawiki dumps](https://www.mediawiki.org/wiki/Manual:Page_restrictions_table) or [API](https://www.mediawiki.org/w/api.php?action=help&modules=query%2Binfo). It has three stages:\n",
    "* Accessing the Page Protection dumps\n",
    "* Accessing the Page Protection API\n",
    "* Example analysis of page protection data (both descriptive statistics and learning a predictive model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Page Protection Dumps\n",
    "This is an example of how to parse through [Mediawiki dumps](https://www.mediawiki.org/wiki/Manual:Page_restrictions_table) and determine [what sorts of edit protections](https://en.wikipedia.org/wiki/Wikipedia:Protection_policy#Overview_of_types_of_protection) are applied to a given Wikipedia article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add other libraries here as necessary\n",
    "import gzip  # necessary for decompressing dump file into text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every language on Wikipedia has its own page restrictions table\n",
    "# you can find all the dbnames (e.g., enwiki) here: https://www.mediawiki.org/w/api.php?action=sitematrix\n",
    "# for example, you could replace the LANGUAGE parameter of 'enwiki' with 'arwiki' to study Arabic Wikipedia\n",
    "LANGUAGE = 'enwiki'\n",
    "# e.g., enwiki -> en.wikipedia (this is necessary for the API section)\n",
    "SITENAME = LANGUAGE.replace('wiki', '.wikipedia')\n",
    "# directory on PAWS server that holds Wikimedia dumps\n",
    "DUMP_DIR = \"/public/dumps/public/{0}/latest/\".format(LANGUAGE)\n",
    "DUMP_FN = '{0}-latest-page_restrictions.sql.gz'.format(LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1M /public/dumps/public/enwiki/latest/enwiki-latest-page_restrictions.sql.gz\r\n"
     ]
    }
   ],
   "source": [
    "# The dataset isn't huge -- 1.1 MB -- so should be quick to process in full\n",
    "!ls -shH \"{DUMP_DIR}{DUMP_FN}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- MySQL dump 10.16  Distrib 10.1.44-MariaDB, for debian-linux-gnu (x86_64)\r\n",
      "--\r\n",
      "-- Host: 10.64.48.13    Database: enwiki\r\n",
      "-- ------------------------------------------------------\r\n",
      "-- Server version\t10.1.43-MariaDB\r\n",
      "\r\n",
      "/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\r\n",
      "/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\r\n",
      "/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\r\n",
      "/*!40101 SET NAMES utf8mb4 */;\r\n",
      "/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;\r\n",
      "/*!40103 SET TIME_ZONE='+00:00' */;\r\n",
      "/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;\r\n",
      "/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;\r\n",
      "/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\r\n",
      "/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\r\n",
      "\r\n",
      "--\r\n",
      "-- Table structure for table `page_restrictions`\r\n",
      "--\r\n",
      "\r\n",
      "DROP TABLE IF EXISTS `page_restrictions`;\r\n",
      "/*!40101 SET @saved_cs_client     = @@character_set_client */;\r\n",
      "/*!40101 SET character_set_client = utf8 */;\r\n",
      "CREATE TABLE `page_restrictions` (\r\n",
      "  `pr_page` int(8) NOT NULL DEFAULT '0',\r\n",
      "  `pr_type` varbinary(255) NOT NULL DEFAULT '',\r\n",
      "  `pr_level` varbinary(255) NOT NULL DEFAULT '',\r\n",
      "  `pr_cascade` tinyint(4) NOT NULL DEFAULT '0',\r\n",
      "  `pr_user` int(10) unsigned DEFAULT NULL,\r\n",
      "  `pr_expiry` varbinary(14) DEFAULT NULL,\r\n",
      "  `pr_id` int(10) unsigned NOT NULL AUTO_INCREMENT,\r\n",
      "  PRIMARY KEY (`pr_id`),\r\n",
      "  UNIQUE KEY `pr_pagetype` (`pr_page`,`pr_type`),\r\n",
      "  KEY `pr_typelevel` (`pr_type`,`pr_level`),\r\n",
      "  KEY `pr_level` (`pr_level`),\r\n",
      "  KEY `pr_cascade` (`pr_cascade`)\r\n",
      ") ENGINE=InnoDB AUTO_INCREMENT=866179 DEFAULT CHARSET=binary ROW_FORMAT=COMPRESSED;\r\n",
      "/*!40101 SET character_set_client = @saved_cs_client */;\r\n",
      "\r\n",
      "--\r\n",
      "-- Dumping data for table `page_restrictions`\r\n",
      "--\r\n",
      "\r\n",
      "/*!40000 ALTER TABLE `page_restrictions` DISABLE KEYS */;\r\n",
      "INSERT INTO `page_restrictions` VALUES (1086732,'edit','sysop',0,NULL,'infinity',1307),(1086732,'move','sysop',0,NULL,'infinity',1308),(1266562,'edit','autoconfirmed',0,NULL,'infinity',1358),(1266562,'move','autoconfirmed',0,NULL,'infinity',1359),(1534334,'edit','autoconfirmed',0,NULL,NULL,1437),(1534334,'move','autoconfirmed',0,NULL,NULL,1438),(1654125,'edit','autoconfirmed',0,NULL,NULL,1664),(1654125,'move','autoconfirmed',0,NULL,NULL,1665),(1654622,'edit','autoconfirmed',0,NULL,NULL,1672),(1654622,'move','autoconfirmed',0,NULL,NULL,1673),(1654633,'edit','autoconfirmed',0,NULL,NULL,1674),(1654633,'move','autoconfirmed',0,NULL,NULL,1675),(1654645,'edit','autoconfirmed',0,NULL,NULL,1676),(1654645,'move','autoconfirmed',0,NULL,NULL,1677),(1654656,'edit','autoconfirmed',0,NULL,NULL,1682),(1654656,'move','autoconfirmed',0,NULL,NULL,1683),(1654662,'edit','autoconfirmed',0,NULL,NULL,1684),(1654662,'move','autoconfirmed',0,NULL,NULL,1685),(1654673,'edit','autoconfirmed',0,NULL,NULL,1686),(16\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first 1000 characters of the page protections dump to see what it looks like\n",
    "# As you can see from the CREATE TABLE statement, each datapoint has 7 fields (pr_page, pr_type, ... , pr_id)\n",
    "# A description of the fields in the data can be found here:\n",
    "#   https://www.mediawiki.org/wiki/Manual:Page_restrictions_table\n",
    "# And the data that we want is on lines that start with INSERT INTO `page_restrictions` VALUES...\n",
    "# The first datapoint (1086732,'edit','sysop',0,NULL,'infinity',1307) can be interpreted as:\n",
    "#   1086732:    page ID 1086732 (en.wikipedia.org/wiki/?curid=1086732)\n",
    "#   'edit':     has edit protections\n",
    "#   'sysop':    that require sysop permissions (https://en.wikipedia.org/wiki/Wikipedia:User_access_levels#Administrator)\n",
    "#   0:          does not cascade to other pages\n",
    "#   NULL:       no user-specific restrictions\n",
    "#   'infinity': restriction does not expire automatically\n",
    "#   1307:       table primary key -- has no meaning by itself\n",
    "\n",
    "!zcat \"{DUMP_DIR}{DUMP_FN}\" | head -46 | cut -c1-1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete example that loops through all page restrictions in the dump file above and extracts data\n",
    "# The Python gzip library will allow you to decompress the file for reading: https://docs.python.org/3/library/gzip.html#gzip.open\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Page Protection APIs\n",
    "The [Page Protection API](https://www.mediawiki.org/w/api.php?action=help&modules=query%2Binfo) can be a much simpler way to access data about page protections for a given article if you know what articles you are interested in and are interested in relatively few articles (e.g., hundreds or low thousands).\n",
    "\n",
    "NOTE: the APIs are up-to-date while the Mediawiki dumps are always at least several days behind -- i.e. for specific snapshots in time -- so the data you get from the Mediawiki dumps might be different from the APIs if permissions have changed to a page's protections in the intervening days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add other libraries here as necessary\n",
    "import mwapi  # useful for accessing Wikimedia API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gather ten random page IDs from the data gathered from the Mediawiki dump to get data for from the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mwapi documentation: https://pypi.org/project/mwapi/\n",
    "# user_agent helps identify the request if there's an issue and is best practice\n",
    "tutorial_label = 'Page Protection API tutorial (mwapi)'\n",
    "# NOTE: it is best practice to include a contact email in user agents\n",
    "# generally this is private information though so do not change it to yours\n",
    "# if you are working in the PAWS environment or adding to a Github repo\n",
    "# for Outreachy, you can leave this as my (isaac's) email or switch it to your Mediawiki username\n",
    "# e.g., Isaac (WMF) for https://www.mediawiki.org/wiki/User:Isaac_(WMF)\n",
    "contact_email = 'isaac@wikimedia.org'\n",
    "session = mwapi.Session('https://{0}.org'.format(SITENAME), user_agent='{0} -- {1}'.format(tutorial_label, contact_email))\n",
    "\n",
    "# TODO: You'll have to add additional parameters here to query the pages you're interested in\n",
    "# API endpoint: https://www.mediawiki.org/w/api.php?action=help&modules=query%2Binfo\n",
    "# More details: https://www.mediawiki.org/wiki/API:Info\n",
    "params = {'action':'query',\n",
    "          'prop':'info'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make request to API for data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: examine API results and compare to data from Mediawiki dump to see if they are the same and explain any discrepancies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Analyses of Page Protection Data\n",
    "Here we show some examples of things we can do with the data that we gathered about the protections for various Wikipedia articles. You'll want to come up with some questions to ask of the data as well. For this, you might need to gather additional data such as:\n",
    "* The [page table](https://www.mediawiki.org/wiki/Manual:Page_table), which, for example, can be found in the `DUMP_DIR` under the name `{LANGUAGE}-latest-page.sql.gz`\n",
    "* Selecting a sample of, for example, 100 articles and getting additional information about them from other [API endpoints](https://www.mediawiki.org/wiki/API:Properties)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add any imports of data analysis / visualization libraries here as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "TODO: give an overview of basic details about page protections and any conclusions you reach based on the analyses you do below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do basic analyses here to understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Model\n",
    "TODO: Train and evaluate a predictive model on the data you gathered for the above descriptive statistics. Describe what you learned from the model or how it would be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Analyses\n",
    "TODO: Describe any additional analyses you can think of that would be interesting (and why) -- even if you are not sure how to do them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
